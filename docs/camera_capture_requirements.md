# Camera Capture Requirements for SkySolve Next

This document summarizes and structures the requirements for camera capture in SkySolve Next, based on the PRD and legacy/modern code review. It is intended for review, enhancement, and as a basis for implementation.

---

## 1. Functional Requirements

### 1.1 Supported Platforms
- **Raspberry Pi (field use):**
  - Use Picamera2/libcamera for direct image capture.
    - If camera model is required for capture APIs, default to HQ RPi camera
  - Support configuration of exposure, gain/ISO, image size.
  - Target cadence: 0.5-1 seconds per frame (based on shutter setting)
- **macOS (development):**
  - Use mock frames for testing (no hardware capture required).
- **Cross-platform (future/stretch):**
  - USB camera support (optional/stretch goal).

### 1.2 Capture Flow
- Capture flow can be in one of three modes: Solve, Align, and Demo/Non-Solve
- In **Solve mode**:
  - Continuously acquire image from camera (Picamera2/libcamera on Pi).
  - Pass image to solver pipeline (Astrometry.net, Tetra3).
  - Publish latest solved coordinates to LX200 server and (optionally) OnStep client.
- In **Align mode**:
  - Continuously acquire image from camera (Picamera2/libcamera on Pi).
  - Display captured image in UI
- In **Non-Solve (on demand) mode**:
  - Acquire image from camera (Picamera2/libcamera on Pi) on demand via UI button.
  - Pass image to solver pipeline (Astrometry.net, Tetra3).
  - Publish latest solved coordinates to LX200 server and (optionally) OnStep client.

### 1.3 Configuration & Control
- Camera settings (exposure, ISO, image size) must be configurable via settings file and/or Web UI.
- Allow switching between demo/mock and real camera capture.
- Provide preview image for UI display.

### 1.4 Error Handling & Diagnostics
- Log camera capture errors with structured logging (level: ERROR).
- Provide status feedback in UI if camera is unavailable or misconfigured.
- Support fallback to non-solve (on demand) mode if camera capture fails.

### 1.5 Concurrency Requirements
- Camera capture and image solving must run concurrently to maximize throughput and responsiveness.
- The system must ensure that a new capture can begin as soon as the previous image is delivered to the solver pipeline.
- Only the most recent image should be solved; if the solver is busy, older images should be discarded to avoid a backlog.
- Use a thread-safe queue or shared variable to pass images from the capture thread to the solve thread, ensuring atomic replacement of obsolete images.
- The preview image in the UI should always reflect the latest captured frame, regardless of whether it has been solved.
- Thread synchronization must be handled to avoid race conditions when sharing image data between threads.

---

## 2. Non-Functional Requirements

- **Performance:**
  - Minimize capture latency to allow new capture to be started as soon as image is delivered to solver pipeline
  - Captured image should be copied to new file prior to sending to solver to allow new capture to occur concurrent with solver
- **Reliability:**
  - Robust error handling for hardware failures.
- **Security:**
  - Do not expose camera controls over network except via authenticated API (future).
- **Extensibility:**
  - Design for future support of additional camera types (USB, network cameras).
    - No specifics, but avoid hard-coding details outside of camera abstraction

---

## 3. Implementation Notes (from legacy/modern code)

- Abstracted camera interface for different capture platforms
- Preview image should be updated after each capture for user feedback.
  - Image should always be latest capture, regardless of whether it was "solved"
- Capture and solve should be in separate threads to allow concurrency
  - If common file name used for image, ensure proper thread synchronization

---

*Generated by GitHub Copilot, 2025-09-02*
